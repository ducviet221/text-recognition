{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1CQOhhPpWXJBe_KhuEoZUP6faDDr7hPDT","authorship_tag":"ABX9TyMgJ6hchTCfoF8W0Y2OYzsE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZNrB7KI_uNH","executionInfo":{"status":"ok","timestamp":1662538248957,"user_tz":-420,"elapsed":10885,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}},"outputId":"d96197ef-eaf7-451e-ed45-1417c8a886b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-ocr\n","  Downloading keras_ocr-0.9.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (0.5.3)\n","Collecting fonttools\n","  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n","\u001b[K     |████████████████████████████████| 957 kB 56.5 MB/s \n","\u001b[?25hRequirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (0.4.0)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (1.8.4)\n","Collecting essential_generators\n","  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n","\u001b[K     |████████████████████████████████| 9.5 MB 48.7 MB/s \n","\u001b[?25hCollecting efficientnet==1.0.0\n","  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (4.64.0)\n","Collecting validators\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Collecting pyclipper\n","  Downloading pyclipper-1.3.0.post3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (604 kB)\n","\u001b[K     |████████████████████████████████| 604 kB 65.9 MB/s \n","\u001b[?25hCollecting keras-applications<=1.0.8,>=1.0.7\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.18.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (1.21.6)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (1.5.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (2.9.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (1.15.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (3.2.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (4.6.0.66)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (1.7.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (7.1.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2.6.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug->keras-ocr) (4.1.1)\n","Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->keras-ocr) (4.4.2)\n","Building wheels for collected packages: validators\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=3691b3d9d1c8c2f7cb4045f9890cdb24609cbc5fb23bc8ed3cb94a3d6d6a116d\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built validators\n","Installing collected packages: keras-applications, validators, pyclipper, fonttools, essential-generators, efficientnet, keras-ocr\n","Successfully installed efficientnet-1.0.0 essential-generators-1.0 fonttools-4.37.1 keras-applications-1.0.8 keras-ocr-0.9.1 pyclipper-1.3.0.post3 validators-0.20.0\n"]}],"source":["!pip install keras-ocr"]},{"cell_type":"code","source":["import os\n","import math\n","import imgaug\n","#A library for image augmentation in machine learning experiments, \n","#particularly convolutional neural networks. Supports the augmentation of images\n","#, keypoints/landmarks, bounding boxes, heatmaps and \n","#segmentation maps in a variety of different ways.\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn.model_selection\n","import tensorflow as tf\n","import keras_ocr\n","import typing"],"metadata":{"id":"InBqsyP__yfp","executionInfo":{"status":"ok","timestamp":1662538266510,"user_tz":-420,"elapsed":4367,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data_dir = '.'"],"metadata":{"id":"53xAHE3-_0pA","executionInfo":{"status":"ok","timestamp":1662538268712,"user_tz":-420,"elapsed":300,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def get_dataset(training_gt_dir,training_images_dir,skip_illegible=False):\n","  dataset=[]\n","  image_files_name = os.listdir(training_images_dir)\n","  label_files_name = os.listdir(training_gt_dir)\n","  for image_file, label_file in zip(image_files_name,label_files_name):\n","        image_path = os.path.join(training_images_dir, image_file )\n","        lines = []\n","        with open(os.path.join(training_gt_dir, label_file), \"r\", encoding=\"utf8\") as f:\n","            current_line: typing.List[typing.Tuple[np.ndarray, str]] = []\n","            for raw_row in f.read().split(\"\\n\"):\n","                if raw_row == \"\":\n","                    lines.append(current_line)\n","                    current_line = []\n","                else:\n","                    row = raw_row.split(\" \")[4:]\n","                    #take from the 4th element onwards\n","                    character = row[-1][1:-1]\n","                    #the last element is the letter\n","                    if character == \"\" and skip_illegible:\n","                        continue\n","                    x1, y1, x2, y2 = map(float, row[:4])\n","                    #get 4 final coordinates of file label execpt last letter\n","                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","                    #cast type to int\n","                    current_line.append(\n","                        (np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]]), character)\n","                    )\n","        lines = [line for line in lines if line]\n","        dataset.append((image_path, lines, 1))\n","  return dataset"],"metadata":{"id":"jSKrvBMf_3WR","executionInfo":{"status":"ok","timestamp":1662538270062,"user_tz":-420,"elapsed":5,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["training_gt_dir=\"/content/drive/MyDrive/OCR/Keras/dataset/labels\"\n","training_images_dir=\"/content/drive/MyDrive/OCR/Keras/dataset/image\""],"metadata":{"id":"FbUaHeCP_6TO","executionInfo":{"status":"ok","timestamp":1662538272537,"user_tz":-420,"elapsed":302,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["dataset=get_dataset(training_gt_dir,training_images_dir,skip_illegible=False)"],"metadata":{"id":"amC8evWgANB-","executionInfo":{"status":"ok","timestamp":1662538354673,"user_tz":-420,"elapsed":37482,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train, validation = sklearn.model_selection.train_test_split(\n","    dataset, train_size=0.8, random_state=42\n",")\n","augmenter = imgaug.augmenters.Sequential([\n","    imgaug.augmenters.Affine(\n","      scale=(1.0, 1.2),\n","      rotate=(-5, 5)\n","      # Apply affine transformations to each image.\n","      # Scale/zoom them, translate/move them, rotate them and shear them.\n","    ),\n","    imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),\n","    #Strengthen or weaken the contrast in each image.\n","    imgaug.augmenters.Multiply((0.8, 1.2), per_channel=0.2)\n","    # Make some images brighter and some darker.\n","    # In 20% of all cases, we sample the multiplier once per channel,\n","    # which can end up changing the color of the images.\n","])\n","generator_kwargs = {'width': 640, 'height': 640}\n","training_image_generator = keras_ocr.datasets.get_detector_image_generator(\n","    labels=train,\n","    augmenter=augmenter,\n","    **generator_kwargs\n",")\n","validation_image_generator = keras_ocr.datasets.get_detector_image_generator(\n","    labels=validation,\n","    **generator_kwargs\n",")"],"metadata":{"id":"y2nKQgqnAa0R","executionInfo":{"status":"ok","timestamp":1662538372721,"user_tz":-420,"elapsed":285,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["detector = keras_ocr.detection.Detector()\n","\n","batch_size = 1\n","training_generator, validation_generator = [\n","    detector.get_batch_generator(\n","        image_generator=image_generator, batch_size=batch_size\n","    ) for image_generator in\n","    [training_image_generator, validation_image_generator]\n","]\n","detector.model.fit_generator(\n","    generator=training_generator,\n","    steps_per_epoch=math.ceil(len(train) / batch_size),\n","    epochs=1000,\n","    workers=0,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5),\n","        #patince: number of epochs with no improvement after which training will be stopped\n","        #the loss for 5 consecutive epochs.\n","        tf.keras.callbacks.CSVLogger(os.path.join(data_dir, 'detector_keras.csv')),\n","        #Callback that streams epoch results to a CSV file.\n","        tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(data_dir, '/content/drive/MyDrive/detector_keras_vinAI.h5'))\n","        #Callback to save the Keras model or model weights at some frequency.\n","    ],\n","\n","    validation_data=validation_generator,\n","    validation_steps=math.ceil(len(validation) / batch_size)\n",")\n","#val_loss: quantity to be monitored."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1um6xeL3AelO","executionInfo":{"status":"ok","timestamp":1662542826590,"user_tz":-420,"elapsed":405743,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}},"outputId":"86aef059-0669-4d23-8e74-3b2ff70001d5"},"execution_count":11,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Looking for /root/.keras-ocr/craft_mlt_25k.h5\n","Downloading /root/.keras-ocr/craft_mlt_25k.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","960/960 [==============================] - ETA: 0s - loss: 0.0026"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras_ocr/tools.py:580: RuntimeWarning: invalid value encountered in double_scalars\n","  rotation = np.arctan((tl[0] - bl[0]) / (tl[1] - bl[1]))\n","/usr/local/lib/python3.7/dist-packages/keras_ocr/tools.py:580: RuntimeWarning: invalid value encountered in long_scalars\n","  rotation = np.arctan((tl[0] - bl[0]) / (tl[1] - bl[1]))\n"]},{"output_type":"stream","name":"stdout","text":["960/960 [==============================] - 669s 679ms/step - loss: 0.0026 - val_loss: 0.4066\n","Epoch 2/1000\n","960/960 [==============================] - 378s 394ms/step - loss: 0.0030 - val_loss: 0.4034\n","Epoch 3/1000\n","960/960 [==============================] - 379s 395ms/step - loss: 0.0039 - val_loss: 0.4042\n","Epoch 4/1000\n","960/960 [==============================] - 380s 396ms/step - loss: 0.0026 - val_loss: 0.4084\n","Epoch 5/1000\n","960/960 [==============================] - 377s 392ms/step - loss: 0.0035 - val_loss: 0.4030\n","Epoch 6/1000\n","960/960 [==============================] - 377s 393ms/step - loss: 0.0028 - val_loss: 0.3994\n","Epoch 7/1000\n","960/960 [==============================] - 376s 392ms/step - loss: 0.0026 - val_loss: 0.4073\n","Epoch 8/1000\n","960/960 [==============================] - 376s 392ms/step - loss: 0.0032 - val_loss: 0.4075\n","Epoch 9/1000\n","960/960 [==============================] - 376s 391ms/step - loss: 0.0040 - val_loss: 0.3998\n","Epoch 10/1000\n","960/960 [==============================] - 378s 394ms/step - loss: 0.0035 - val_loss: 0.4016\n","Epoch 11/1000\n","960/960 [==============================] - 377s 393ms/step - loss: 0.0035 - val_loss: 0.4069\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6f805f55d0>"]},"metadata":{},"execution_count":11}]}]}